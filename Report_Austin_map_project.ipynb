{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Project\n",
    "\n",
    "**author: Bob Cross**\n",
    "\n",
    "**date: December 15, 2016**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "I chose Austin, Texas as the area for this project. I am new to this city and thought this project would assist me in exploring Austin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Problems in the Map\n",
    "\n",
    "After taking a sample of the 1.16 GB dataset using sample_region.py, I used three techniques to identify problems in the sample:\n",
    "\n",
    "Utilized Sublime to view portions of the data in it's original form.  \n",
    "Analyzed the audit.py script output to view unusual street names and postal codes.  \n",
    "Analyzed the CSV files created by the process_osm. script to view the data (in schema.md format) before and after cleaning code was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map\n",
    "Simplified versions of code for audit and cleaning the following problems is presented below.\n",
    "\n",
    "### Overabbreviated street names\n",
    "Spell out over abbreviated street tyoes:\n",
    ">import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"sample.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    pprint.pprint (dict(street_types))\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping.keys():\n",
    "            print 'Before: ', name\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "            print 'After: ', name\n",
    "\n",
    "\n",
    "    return name\n",
    "    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erroneous City names in dataset\n",
    "\n",
    ">import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "#audit way tags for unexpected city names in Austin map\n",
    "\n",
    "osmfile = \"sample.osm\"\n",
    "\n",
    "expected = (\"Austin\", \"Pflugerville\", \"Round Rock\")\n",
    "\n",
    "def is_city_name(elem):\n",
    "    return (elem.attrib['k'] ==\"addr:city\")\n",
    "\n",
    "def audit_city(osmfile):\n",
    "     city_file = open(osmfile, \"r\")\n",
    "     for event, elem in ET.iterparse(city_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:city':\n",
    "                    city = tag.attrib['v'].strip()\n",
    "                    if city not in expected: \n",
    "                        print city\n",
    "                        \n",
    "                         \n",
    "     city_file.close()\n",
    "\n",
    "audit_city(\"sample.osm\")\n",
    "\n",
    "#audit of sample file shows names which appear to be outside of what would be considered Austin (eg Buda > 60mi away)\n",
    "#this would require edit specific entries; these can be ignore for analysis purposes in most cases with no material effect\n",
    "\n",
    "\n",
    ">Manchaca\n",
    "Cedar Park, TX\n",
    "Buda\n",
    "Sunset Valley\n",
    "Buda\n",
    "Lakeway\n",
    "Sunset Valley\n",
    "Cedar Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postal Codes\n",
    "\n",
    "sqlite> SELECT tags.value, COUNT(*) as count  \n",
    "...> FROM (SELECT * FROM nodes_tags  \n",
    "...>       UNION ALL  \n",
    "...>       SELECT * FROM ways_tags) tags    \n",
    "...> WHERE tags.key='postcode'  \n",
    "...> GROUP BY tags.value  \n",
    "...> ORDER BY count DESC;\n",
    "\n",
    "abbreviated results of unusual values:  \n",
    "Texas|2  \n",
    "78724-1199|10   \n",
    "78728-1275|2     \n",
    "78754-5701|2   \n",
    "78759-3504|2  \n",
    "78704-5639|1  \n",
    "78704-7205|1   \n",
    "78753-4150|1   \n",
    "78758-7008|1   \n",
    "78758-7013|1  \n",
    "TX 78613|1  \n",
    "TX 78724|1  \n",
    "TX 78728|1  \n",
    "TX 78735|1  \n",
    "TX 78745|1  \n",
    "TX 78758|1  \n",
    "\n",
    "removal of the items listed as \"Texas\"; \"TX\" pre-fix and four digit extensions can be ignored in analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "\n",
    "### File sizes\n",
    "\n",
    "austin_map.osm ......... 1.16 GB  \n",
    "austin_map.db .......... 773 MB  \n",
    "nodes.csv ............. 499 MB  \n",
    "nodes_tags.csv ........ 9 MB  \n",
    "ways.csv .............. 40 MB  \n",
    "ways_tags.csv ......... 144 MB  \n",
    "ways_nodes.cv ......... 59 MB\n",
    "\n",
    "for validation and data familiarity:  \n",
    "austin_map_sample.osm .... 59 MB  \n",
    "test_sample.osm .......... 9 MB\n",
    "\n",
    "\n",
    "### Number of nodes\n",
    "\n",
    "sqlite> SELECT COUNT(*) FROM nodes;  \n",
    "5,358,645\n",
    "\n",
    "sqlite> SELECT COUNT(*) FROM nodes_tags;  \n",
    "2,011,149\n",
    "\n",
    "\n",
    "### Number of ways, ways_nodes and ways_tags\n",
    "\n",
    "sqlite> SELECT COUNT(*) FROM ways;  \n",
    "564388\n",
    "\n",
    "sqlite> SELECT COUNT(*) FROM ways_nodes;  \n",
    "58,992,639\n",
    "\n",
    "SELECT COUNT(*) FROM ways_nodes;  \n",
    "5,892,639\n",
    "\n",
    "\n",
    "### Number of unique users\n",
    "\n",
    "sqlite> SELECT COUNT(DISTINCT(e.uid))  \n",
    "        FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;  \n",
    "1644\n",
    "\n",
    "\n",
    "### Top 10 contributing users\n",
    "\n",
    "sqlite> SELECT e.user, COUNT(*) as num  \n",
    "...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e  \n",
    "...> GROUP BY e.user  \n",
    "...> ORDER BY num DESC  \n",
    "...> LIMIT 10;  \n",
    "patisilva_atxbuildings|2492624  \n",
    "ccjjmartin_atxbuildings|1062000  \n",
    "ccjjmartin__atxbuildings|834577  \n",
    "jseppi_atxbuildings|273706  \n",
    "wilsaj_atxbuildings|249835  \n",
    "kkt_atxbuildings|157845  \n",
    "lyzidiamond_atxbuildings|135318  \n",
    "woodpeck_fixbot|77816  \n",
    "johnclary_axtbuildings|48232  \n",
    "richlv|46822\n",
    "\n",
    "### Number of users with only 1 posting\n",
    "\n",
    "sqlite> SELECT COUNT(*)  \n",
    "...> FROM  \n",
    "...> (SELECT e.user, COUNT(*) as num  \n",
    "...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e  \n",
    "...> GROUP BY e.user  \n",
    "...> HAVING num=1)  u;  \n",
    "238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data Exploration\n",
    "\n",
    "### Top 10 appearing amenities\n",
    "\n",
    "sqlite> SELECT value, COUNT(*) as num  \n",
    "...> FROM nodes_tags  \n",
    "...> WHERE key='amenity'  \n",
    "...> GROUP BY value  \n",
    "...> ORDER BY num DESC  \n",
    "...> LIMIT 10;\n",
    "\n",
    "parking|1885  \n",
    "restaurant|700  \n",
    "waste_basket|601  \n",
    "fast_food|501  \n",
    "school|437  \n",
    "place_of_worship|413  \n",
    "bench|359  \n",
    "fuel|347  \n",
    "shelter|230  \n",
    "bank|150\n",
    "\n",
    "### Most popular cuisines\n",
    "\n",
    "sqlite> SELECT nodes_tags.value, COUNT(*) as num  \n",
    "...> FROM nodes_tags  \n",
    "...>     JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i  \n",
    "...>     ON nodes_tags.id=i.id  \n",
    "...> WHERE nodes_tags.key='cuisine'  \n",
    "...> GROUP BY nodes_tags.value  \n",
    "...> ORDER BY num DESC  \n",
    "...> LIMIT 10;  \n",
    "mexican|60  \n",
    "american|27  \n",
    "pizza|23  \n",
    "chinese|22  \n",
    "indian|14  \n",
    "sandwich|14  \n",
    "italian|13  \n",
    "regional|13  \n",
    "sushi|13  \n",
    "thai|13\n",
    "\n",
    "\n",
    "### Biggest religion\n",
    "\n",
    "sqlite> SELECT nodes_tags.value, COUNT(*) as num  \n",
    "...> FROM nodes_tags  \n",
    "...>     JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i  \n",
    "...>     ON nodes_tags.id=i.id  \n",
    "...> WHERE nodes_tags.key='religion'  \n",
    "...> GROUP BY nodes_tags.value  \n",
    "...> ORDER BY num DESC  \n",
    "...> LIMIT 1;  \n",
    "christian|367\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Improvement\n",
    "\n",
    "Classification issues from original source input is one of the most significant issues with this dataset and one of the most challenging to address. This is most often the cases with new contributors to the dataset. A periodic scrubb of input from contributors with less than 5 entries may effectively address this concern.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Austin OpenStreetMap dataset is a quite large and a bit messy. However, I believe the dataset is not materially deficint for the analysis purposes of this project. By quwrying the dataset, I learned a number of new things about Austin which will benefit me as I continue to explore this town. The dataset is very useful, though areas for improvement exist.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
